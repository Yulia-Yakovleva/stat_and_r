---
title: "Отчет по проекту_2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

check.packages <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg)) 
        install.packages(new.pkg, dependencies = TRUE)
    sapply(pkg, require, character.only = TRUE)
}

packages <- c("MASS", "dplyr", "ggplot2", "gridExtra", "car", "cowplot")
check.packages(packages)
```

### 0. Организационная часть

Для работы над проектом подгружаем датафрейм *Boston* из пакета **MASS**
```{r, echo = T, eval = T, include = T}
data(Boston)
```
Список используемых в работе библиотек: **MASS**, **dplyr**, **ggplot2**, **gridExtra**, **car**, **cowplot**.

### 1. Знакомство с данными и их предобработка

Посмотрим на наши данные, их структуру, есть ли пропущенные значения:
```{r, set-options, echo = T, eval = T, include = T}
options(width = 100)
head(Boston)
str(Boston)
colSums(is.na(Boston))
```

Переведем переменные **chas** и **rad** в факторные переменные
```{r, echo = T, eval = T, include = T, message = F}
table(Boston$chas)
table(Boston$rad)
Boston$chas <- factor(Boston$chas, levels = c("0", "1"), labels = c("0", "1"))
Boston$rad <- factor(Boston$rad, 
                     levels = c("1", "2", "3", "4", "5", "6", "7", "8", "24"), 
                     labels = c("1", "2", "3", "4", "5", "6", "7", "8", "24"))
```

### 2. Работа над обязатеьной частью. Пункт 1

Проведем стандартизацию количественных предикторов:
```{r, echo = T, eval = T, include = T}
scaled_Boston <- Boston
scaled_Boston[, c(1:3, 5:8, 10:13)] <- scale(scaled_Boston[, c(1:3, 5:8, 10:13)])
```

Отлично! Проверим наличие отскоков с помощью точечных диаграмм Кливленда:

```{r, echo = T, eval = T, include = T}
gg_dot <- ggplot(scaled_Boston, aes(y = 1:nrow(scaled_Boston))) + geom_point() + ylab('Индекс')
Pl1 <- gg_dot + aes(x = crim)
Pl2 <- gg_dot + aes(x = zn)
Pl3 <- gg_dot + aes(x = indus)
Pl4 <- gg_dot + aes(x = chas)
Pl5 <- gg_dot + aes(x = nox)
Pl6 <- gg_dot + aes(x = rm)
Pl7 <- gg_dot + aes(x = age)
Pl8 <- gg_dot + aes(x = dis)
Pl9 <- gg_dot + aes(x = rad)
Pl10 <- gg_dot + aes(x = tax)
Pl11 <- gg_dot + aes(x = ptratio)
Pl12 <- gg_dot + aes(x = black)
Pl13 <- gg_dot + aes(x = lstat)
Pl14 <- gg_dot + aes(x = medv)
plot_grid(Pl1, Pl2, Pl3, Pl4, Pl5, Pl6, 
          Pl7, Pl8, Pl9, Pl10, Pl11, Pl12, Pl13, Pl14, ncol = 3, nrow = 5) + theme_minimal()
```

Да, есть много отскакивающих значений, но имеет ли право мы их убирать? Я считаю, что нет, поскольку по аннотации данных нам трудно предположить, имела ли место погрешность при сборе данных или это особенность данных из-за наличия автокорреляции.

Строим полную линейную модель без учета взаимодействия предикторов. От себя добавлю, что особенно при появлении дискретных переменных необходимо учитывать взаимодействия дискретных и непрерывных предикторов, так что по-хорошему это сделать нужно для полной модели, но от нас в задании почему-то это не требуется...
```{r, echo = F, eval = T, include = T}
mod1 <- lm(medv ~ ., data = scaled_Boston)
summary(mod1)
```
Классно!

### Работа над обязательной часть. Пункт 2. Диагностика модели

#### а) Проверка линейности взаимосвязи

Первым делом можем построить график попарной зависимости всего от всех и посмотреть на потенциальные проблемы:
```{r, echo = F, eval = T, include = T}
pairs(scaled_Boston)
```
  
Видим, что проблем хватает почти по всем фронтам. Некоторые переменные, предположительно, взаимосвязаны друг с другом.
  
Чтобы окончательно удостовериться, есть ли проблемы с нелинейностью связи, посмотрим на график остатков от предсказанных значений:
  
```{r, echo = F, eval = T, include = T}
mod1_diag <- fortify(mod1)
gg_resid <- ggplot(data = mod1_diag, aes(x = .fitted, y = .stdresid)) + 
  geom_point() + 
  geom_hline(yintercept = 0) +
  geom_smooth(method = "lm") +
  geom_hline(yintercept = 2, color = "red") +
  geom_hline(yintercept = -2, color = "red") +
  theme_minimal()
gg_resid_1 <- gg_resid + labs(x = "Предсказанные значения", y = "Остатки", title = "График остатков от предсказанных значений")
gg_resid_1
```
  
Да, я полагаю, что есть проблемы с нелинейностью взаимосвязи.

#### б) Проверка влиятельных наблюдений с помощью графика расстояний Кука

Расстояние Кука описывает, как повлияет на модель удаление данного наблюдения. Зависит одновременно от величины остатков и силы воздействия наблюдения.  
Как нам выбрать условное пороговое значение?  
Наблюдение будем считать выбросом, если:  
Значение больше единицы (это мягкий порог, но для работы нам его будет достаточно)  

```{r, echo = F, eval = T, include = T}
gg_cook_1 <- ggplot(mod1_diag, aes(x = 1:nrow(mod1_diag), y = .cooksd)) + 
  geom_bar(stat = "identity") +
  labs(x = "Предсказанные значения", y = "Расстояние Кука", title = "График расстояния Кука") + theme_minimal()
gg_cook_1
```

В случае выставления более жесткого порога (4/n - p), где n - объем выборки, p - число параметров, ситуация вырисовывается совсем иная:

```{r, echo = F, eval = T, include = T}
gg_cook_2 <- ggplot(mod1_diag, aes(x = 1:nrow(mod1_diag), y = .cooksd)) + 
  geom_bar(stat = "identity") +
  geom_hline(yintercept = 4/(506 - 24), color = "red") + 
  labs(x = "Предсказанные значения", y = "Расстояние Кука", title = "График расстояния Кука") + theme_minimal()
gg_cook_2
```

Формально нам ничто не мешает использовать мягкий порог и утвержать, что влиятельные наблюдения у нас отсутствуют.

#### в) Независимость наблюдений (есть ли автокорреляция)

Об автокорреляции имет смысл говорить, если у нас есть ряд наблюдений во времени или пространстве.

Существуют различные способы проверки временной автокорреляции. Например, график автокорреляционной функции остатков (ACF-plot) покажет корреляции с разными лагами. Критерий Дарбина-Уотсона (значимость автокорреляции 1-го порядка). Но эти способы годятся, если наблюдения в ряду расположены через равномерные интервалы. Насколько понятно из датафрейма, временной автокорреляции у нас нет.

Для проверки пространственных автокорреляций можно использовать вариограммы или I Морана, но мы будем использовать способ намного лучше -- график остатков от переменных, входящих в модель!

На графике остатков от переменных, входящих в модель и не входящих в нее мы сможем увидеть намного больше, чем наличие автокорреляции -- мы видим "паттерны" в широком смысле. Это могут быть не только автокорреляции, но и признаки нелинейной зависимости или невключенных взаимодействий предикторов и т.п.

```{r, echo = F, eval = T, include = T}
res_1 <- gg_resid + aes(x = crim) + theme_minimal()
res_2 <- gg_resid + aes(x = zn) + theme_minimal()
res_3 <- gg_resid + aes(x = indus) + theme_minimal()
res_4 <- gg_resid + aes(x = chas) + theme_minimal()
res_5 <- gg_resid + aes(x = nox) + theme_minimal()
res_6 <- gg_resid + aes(x = rm) + theme_minimal()
res_7 <- gg_resid + aes(x = age) + theme_minimal()
res_8 <- gg_resid + aes(x = dis) + theme_minimal()
res_9 <- gg_resid + aes(x = rad) + theme_minimal()
res_10 <- gg_resid + aes(x = tax) + theme_minimal()
res_11 <- gg_resid + aes(x = ptratio) + theme_minimal()
res_12 <- gg_resid + aes(x = black) + theme_minimal()
res_13 <- gg_resid + aes(x = lstat) + theme_minimal()

grid.arrange(res_1, res_2, res_3, res_4, res_5, 
             res_6, res_7, res_8, res_9, res_10,
             res_11, res_12, res_13, nrow = 3, top = "График остатков от предикторов в модели и вне")
```

Видим паттерны для многих переменных: с данными не все хорошо. Вполне может быть, что присутствует пространственная автокорреляция в связи с тем, что Бостон -- город большой, а переменная, которая бы отражала район, не внесена. В свою очередь зависимости от района благополучность обстановки по разным параметрам может сильно варьировать, оттуда и подозрения на автокорреляцию.

#### г) Проверка на нормальность распределения остатков и постянство дисперсии

Есть формальные тесты на нормальность распределения остатков, но у формальных тестов тоже есть свои условия применимости, при больших выборках они скорее покажут, что значимы даже небольшие отклонения от нормального распределения. Тесты, которые используются в линейной регрессии устойчивы к небольшим отклонениям от нормального распределения, но лучший способ проверки -- это квантильный график остатков.

```{r, echo = F, eval = T, include = T}
qqPlot(mod1, xlab = "Теоретические квантили", ylab = "Стьюдентизированные остатки", main = "Квантильный график остатков", id = FALSE)
```

По оси X -- квантили теоретического распределения, по оси Y -- квантили остатков модели. Если наблюдаемое распределение соответствует теоретическому. то точки должны лечь вдоль прямой по диагонали графика. На графике изображены стюдентизированные остатки, которые подчинаются t-распределению. Отклонения от нормального распределения остатков незначительны.
  
Наконец, одно из самых важных условий: постоянство дисперсии, она же гомогенность дисперсии или гомоскедастичность. Многие тесты чувствительны к гетероскедастичности, поэтому это самое важное условие!
  
Опять же есть формальные тесты (тест Бройша-Пагана, тест Кокрана), но у формальных тестов тоже есть свои условия применимости, и многие сами неустойчивы к гетероскедастичности. При больших выборках формальные тесты покажут, что значима даже небольшая гетероскедастичность, поэтому лучший способ проверки на гомогенность дисперсий -- график остатков, который мы уже строили. Наличие гетероскедастичности еще раз убеждает нас в том, что модель, которую мы изначально построили никуда не годится.

### Работа над обязательной частью. Пункт 3

Поскольку полная модель никуда совершенно не годится, будем строить график предсказанных значений для оптимальной модели!

### Работа над дополнительной частью. Пункт 1

Для начала нужно оценить, какую долю изменчивости конкретного предиктора могут объяснить другие предикторы, т.е. насколько предикторы независимы. Из предыдущих шагов мы выяснили, что возможна проблема с мультиколлинеарностью. Попарный график намекет на то, что может быть линейная зависимость между предикторами. При наличии мультиколлинеарности оценки параметров неточны, а значит сложно интерпретировать влияние предикторов на отклик.  
  
#### Пробуем решить сложность с мультиколлинеарностью

Чтобы исключить такие подводные камни, делаем проверку на мультиколлинеарность подсчетом коэффициента раздутия дисперсии (VIF).
```{r, echo = F, eval = T, include = T}
vif(mod1)
```

Да, в нашей модели сильная мультиколлинеарность. Удаляем предиктор **rad**, поскольку у него самый большой VIF и строим новую модель.  

```{r, echo = F, eval = T, include = T}
mod2 <- lm(formula = medv ~ crim + zn + indus + chas + nox + rm + age + dis + tax + ptratio + black + lstat, data = scaled_Boston)
vif(mod2)
```

Теперь удаляем предиктор **nox** и снова перестраиваем модель.

```{r, echo = F, eval = T, include = T}
mod3 <- lm(formula = medv ~ crim + zn + indus + chas + rm + age + dis + tax + ptratio + black + lstat, data = scaled_Boston)
vif(mod3)
```

Все еще есть избыточные предикторы, которые нас не устраивают. Удаляем предиктор **dis**.
```{r, echo = F, eval = T, include = T}
mod4 <- lm(formula = medv ~ crim + zn + indus + chas + rm + age + tax + ptratio + black + lstat, data = scaled_Boston)
vif(mod4)
```

К сожалению, все еще есть предикторы с коэффициентом раздутия дисперсии больше трех. Если бесконечно выкидывать предикторы до оптимального VIF для всех предикторов, то есть шанс избавиться предиктора, без которого модель станет намного хуже, поэтому все равно нужен компромисс. Попробуем работать с такой моделлью дальше.

#### Пошаговый отбор оптимальной модели

Тестируем значимость всех предикторов за один раз, затем выбираем предиктор, удаление которого меньше всего ухудшает модель:
```{r, echo = F, eval = T, include = T}
drop1(mod4, test = "F")
```

Переменную **indus** можно спокойно исключить из модели. Повторяем процедуру:
```{r, echo = F, eval = T, include = T}
mod5 <- update(mod4, . ~ . - indus)
drop1(mod5, test = "F")
```

Исключаем **tax**:
```{r, echo = F, eval = T, include = T}
mod6 <- update(mod5, . ~ . - tax)
drop1(mod6, test = "F")
```

Исключаем **zn**:
```{r, echo = F, eval = T, include = T}
mod7 <- update(mod6, . ~ . - zn)
drop1(mod7, test = "F")
```

Возможно, где-то на этом или предыдущем шаге хочется остановиться, помятуя правило "полная модель всегда будет лучше вложенной", однако попробуем довести дело до конца и посмотреть, что станет с финальной версией модели.

Исключаем **crim**:
```{r, echo = F, eval = T, include = T}
mod8 <- update(mod7, . ~ . - crim)
drop1(mod8, test = "F")
```

Исключаем последний незначимый факток **age**:
```{r, echo = F, eval = T, include = T}
mod9 <- update(mod8, . ~ . - age)
drop1(mod9, test = "F")
```

Ура! Наша модель готова!

#### Анализ полученной модели

##### Проверка на линейность взаимосвязи с помощью графика остатков предсказанных значений:

```{r, echo = F, eval = T, include = T}
mod9_diag <- fortify(mod9)
gg_resid <- ggplot(data = mod9_diag, aes(x = .fitted, y = .stdresid)) + 
  geom_point() + 
  geom_hline(yintercept = 0) +
  geom_smooth(method = "lm") +
  geom_hline(yintercept = 2, color = "red") +
  geom_hline(yintercept = -2, color = "red") +
  theme_minimal()
gg_resid_2 <- gg_resid + labs(x = "Предсказанные значения", y = "Остатки", title = "График остатков от предсказанных значений")
gg_resid_2
```

Однозначно видим, что лучше не стало... может ли это быть связано с тем, что мы не дошли до конца с искоренением мультиколлинеарности?..  
```{r, echo = F, eval = T, include = T}
vif(mod9)
summary(mod9)
```  
Нет, дело не в этом. Хорошо, идем дальше...  

##### Проверка влиятельных наблюдений с помощью графика расстояний Кука

```{r, echo = F, eval = T, include = T}
gg_cook_3 <- ggplot(mod9_diag, aes(x = 1:nrow(mod9_diag), y = .cooksd)) + 
  geom_bar(stat = "identity") +
  labs(x = "Предсказанные значения", y = "Расстояние Кука", title = "График расстояния Кука") + theme_minimal()
gg_cook_3
```

Все хорошо, влиятельные наблюдения отсутствуют.  

##### Нормальность распределения остатков

```{r, echo = F, eval = T, include = T}
qqPlot(mod9, xlab = "Теоретические квантили", ylab = "Стьюдентизированные остатки", main = "Квантильный график остатков", id = FALSE)
```

Распределение остатков отклоняется от нормального, что не очень хорошо, но та же ситуация была и в полной модели.

#### Проверка неучтенных зависимостей

Согласно графику остатков от предикторов, не вошедших в данную модель, построенному ранее в пункте в), неучтенных зависимостей не обнаружено. Посмотрим на график остатков от предикторов, пошедших в данную модель еще раз:

```{r, echo = F, eval = T, include = T}
res_4 <- gg_resid + aes(x = chas) + theme_minimal()
res_6 <- gg_resid + aes(x = rm) + theme_minimal()
res_11 <- gg_resid + aes(x = ptratio) + theme_minimal()
res_12 <- gg_resid + aes(x = black) + theme_minimal()
res_13 <- gg_resid + aes(x = lstat) + theme_minimal()

grid.arrange(res_4, res_6, res_11, res_12, res_13, nrow = 2, top = "График остатков от предикторов в модели")
```

Разберем то, что видим поподробнее. Так как переменная chas является факторной, сказать ничего касательно характера паттерна мы не особо можем. Зависимость остатков от *rm* имеет нелинейный паттерн, что заставляет задуматься о том, что, возможно, линейная модель была использована некорректно. На графиках от *black* и *lstat* также видим легкий нелинейный паттерн.

Что мы могли сделать не так? Возможно, все-таки стоило учитывать взаимодействия предикторов...

Посмотрим еще раз на нашу финальную модель:
```{r, echo = F, eval = T, include = T}
summary(mod9)
```

Наибольший по модулю коэффициент обладает переменная **lstat**. Построим от нее график предсказания стоимости:  

```{r, echo = F, eval = T, include = T}
MyData <- data.frame(
  lstat = seq(min(scaled_Boston$lstat), max(scaled_Boston$lstat), length.out = 1000),
  rm = mean(scaled_Boston$rm),
  ptratio = mean(scaled_Boston$ptratio),
  black = mean(scaled_Boston$black),
  chas = as.factor(c(0, 1))
  )

Predictions <- predict(mod9, newdata = MyData,  interval = 'confidence')
MyData <- data.frame(MyData, Predictions)

Pl_predict <- ggplot(MyData, aes(x = lstat, y = fit, fill  = chas)) + 
  geom_ribbon(alpha = 0.2, aes(ymin = lwr, ymax = upr)) +
  geom_line() + 
  ggtitle("График предсказания стоимости от процента населения с низким статусом") + theme_minimal() + 
  labs(x = "Процент населения с низким статусом", y = "Предсказанные значения средней стоимости",
       fill = "Река Чарльза") +
  scale_fill_discrete(labels = c("Если путь связан с рекой", "Другое"))

Pl_predict 
```
  
Запишем наше уравнение линейной модели:  

```
medv = 22.30 + 3.32 * chas1 + 3.27 * rm - 1.86 * ptratio + 0.92 * black - 3.67 * lstat
```

Проинтепретируем результаты нашей модели:  
Представленная модель описывает примерно 69% суммарной изменчивости переменной *medv*, что не очень много. Также диагностика модели показала нелинейность связи и отклонение остатков от нормальног, что заставляет сомневаться в качестве подобной модели.
**Intercept** -- предсказанное значение переменной *medv* от *chas* для уровня "Если путь связан с рекой", с учетом того, что все остальные переменные равны нулю.  
**chas1** -- предсказанное значение *medv* для уровня "Другое", с учетом того, что все остальные переменные равны нулю.  
Для остальных предикторов (**rm**, **pration**, **black**, **lstat**), поскольку они являются непрерывными, интепретация будет такова: при изменении предиктора на одно стандартное отклонение значение переменной *medv* изменится НА значение коэффициента предиктора.

Всё!