---
title: "Отчет по проекту_3"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

check.packages <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg)) 
        install.packages(new.pkg, dependencies = TRUE)
    sapply(pkg, require, character.only = TRUE)
}

packages <- c("readxl", "stringr", "vegan", "dplyr", "ggplot2", "car", "multcomp", "cowplot", "rgl", "pca3d", "factoextra", "gridExtra")
check.packages(packages)
```

### 0. Организационная часть
  
Список используемых в работе библиотек: **readxl**, **stringr**, **vegan**, **dplyr**, **ggplot2**, **factoextra**, **cowplot**, **car**, **multcomp**, **pca3d**, **gridExtra**.
  
Для работы необходимо задать путь до директории, содержащей распакованные файлы для работы над проектом:
```{r, echo = T, eval = T, include = T}
dir_path <- '/home/yulia/stat_and_r/'
```
  
Теперь можно подгружать данные:
```{r, echo = T, eval = T, include = T}
data <- read_excel(paste(dir_path, 'Data_Cortex_Nuclear.xls', sep = ''))
```
  
### Блок 1. Описание датасета
  
Знакомимся с данными:
```{r, echo = T, eval = T, include = T}
str(data)
```
  
Итак, что мы знаем об этом датасете?  
Датафрейм содержит данные по уровню продукции **77** белков. Есть **38** контрольных мышей (нормальных) и **34** тышей с трисомией (синдромом Дауна), всего **72** мышки. Было произведено **15** измерений для каждой белковой пробы/мышки. Таким образом, для контрольных мышек 38\*15 (это 570) измерений, а для мышей с трисомией 34\*15 (это 510) измерений. Итого датафрейм содержит **1080** измерений на белок.
  
Какие группы можно выделить?  
Мышек можно разделить на групы соответствующим образом:  
  
**c-CS-s**: контрольные мыши, стимулированные к обучению, кололи физраствором (9 мышей)  
**c-CS-m**: контрольные мыши, стимулированные к обучению, кололи мемантином (10 мышей)  
**c-SC-s**: контрольные мыши, нестимулированные к обучению, кололи физраствором (9 мышей)  
**c-SC-m**: контрольные мыши, нестимулированные к обучению, кололи мемантином (10 мышей)  

**t-CS-s**: мыши с трисомией, стимулированные к обучению, кололи физраствором (7 мышей)  
**t-CS-m**: мыши с трисомией, стимулированные к обучению, кололи мемантином (9 мышей)  
**t-SC-s**: мыши с трисомией, нестимулированные к обучению, кололи физраствором (9 мышей)  
**t-SC-m:** мыши с трисомией, нестимулированные к обучению, кололи мемантином (9 мышей)  
  
ID каждой мышки в соответствии с этим можно читать, как *АЙДИМЫШИ_НОМЕР-ИЗМЕРЕНИЯ*.  
Имеет смысл разделить айди мыши и номер измерения на отдельные колонки (и не умереть от регулярных выражений):  
```{r, echo = T, eval = T, include = T}
data$ExperimentID <-  as.factor(gsub('.*_', '', data$MouseID))
data$Mouse <- as.factor(gsub('_.*', '', data$MouseID))
```
  
Отлично!  
  
Насколько группы сбалансированы?  
Можно сказать, что группы более менее сбалансированны, в основном мы имеем 9 мышей. Не очень хорошо, что для группы **t-CS-s** мы имеем 7 мышей, это меньше, чем 9-10, т.е. могло бы быть и лучше, но теперь с этим ничего уже не сделаешь, выкидывать эту группу из данных мы все равно прав не имеем. 
  
Какое количество полных наблюдений?  
```{r, echo = T, eval = T, include = T}
data[!complete.cases(data), ]
```
  
Жуть! Половина наших мыше-измерений (а конкретно **528**) может содержать пропущенные значения хотя бы для одного белка! Только **552** значения являются полными, и это страшно.  
Хорошо бы понять, как эти пропущенные значения разбросаны по датафрейму, возможно, достаточно будет выкинуть пару белков или пару мышек, и отряд не заметит потери бойца?  
```{r, echo = T, eval = T, include = T}
tmp <- sort(colSums(is.na(data)), decreasing =  TRUE)
tmp[tmp > 0]
```
  
Да, у нас просто дикое количество пропущенных значений для белков **BCL2_N** (285), **H3MeK4_N** (270), **BAD_N** (213), **EGR1_N** (210), **H3AcK18_N** (180), **pCFOS_N** (75). Дает ли нам это знание право отбросить эти белки?  
Представим, что у каждой мышки из семидесяти двух внезапно потерялось по трем измерениям для любого белка, в таком случае мы бы имели **216** пропущенных значений. Кажется, что в сумме это много, но на деле, от мышки не убудет, ведь ее измеряли несколько раз! Или представим, что все измерения для каждого белка сделаны, но в пяти группах умерло по одной мышке. Поскольку дохлых мышей мы измерить не сможем, то потеряем **измерений**. Это тоже кажется много, но в целом от группы не убудет, особенно если это не влияет на общую сбалансированность групп.  
**Вывод:**  
Мы не можем просто так выкинуть пропущенные значения, как следует не разобравшись!  
  
Что же делать?  
**1)** Выкинуть все NA
# Посмотрим, сколько измерений останется на каждую мышь, если выкинуть все измерения, содержащие NA
```{r, echo = T, eval = T, include = T}
tmp <- sort(table(data[complete.cases(data), ]$Mouse), decreasing =  TRUE)
tmp[tmp > 0]
```
  
Ужасно! Можно увидеть,что примерно половина мышей в таком случае лишится хотя бы каких-либо измерений! Это откровенное зверство такой исход нас не устраивает...  
**2)** Отбросить белки, которые содержат много *NA*. Такой исход приходит на ум следующим после того, как мы отказались выкидывать все пропущенные значения. С одной стороны, это звучит разумно, ведь мы не хотим ничем заменять значения, о которых мы ничего не знаем. С другой стороны, наши группы сбалансированы неидеально. Если в одной группе 7 мышей, и в ней измерены все, а в другой группе 10 мышей, и в ней одну не померили, то это звучит не так страшно. В итоге это приводит нас к варианту 3:  
**З)** Смотреть, из какой группы пришла мышка, если это не группа с самым маленьким числом мышек, то мы можем себе позволить ее выкинуть из анализа. Но в таком случае из-за проблем с данными по одному-двум белкам мы можем лишиться других данных, это тоже не очень хороший вариант, поэтому...  
**4)** Заменяем пропущенные значения на внутриклассовую среднюю температуру по больнице. Не очень самый идеальный вариант, но лучше, чем предложенные выше!  
  
Делаем!  
```{r, echo = T, eval = T, include = T, message = F}
good_data <- data %>% group_by(data$class) %>% 
  mutate_at(vars(-group_cols()), list( ~ ifelse(is.na(.), mean(., na.rm = TRUE),.)))
```
  
Переменные **MouseID**, **Genotype**, **Treatment**, **Behavior**, **class** являются факторными переменными, так переведем же их в фактор!
```{r, echo = T, eval = T, include = T}
good_data$MouseID <- as.factor(good_data$MouseID)
good_data$Genotype <- as.factor(good_data$Genotype)
good_data$Treatment <- as.factor(good_data$Treatment)
good_data$Behavior <- as.factor(good_data$Behavior)
good_data$class <- as.factor(good_data$class)
str(good_data)
```  
  
Проверяем, что все пошло по плану:  
```{r, echo = T, eval = T, include = T}
tmp <- colSums(data[!complete.cases(good_data), ])
tmp[tmp > 0]
```
  
Отлично! Данные приведены в порядок, можно приступать к следующему блоку.  
  
### Блок 2. Есть ли различия в уровне продукции BDNF_N в зависимости от класса?
  
Дело пахнет ~~жареным~~ дисперсионным анализом. Есть два пути решения нашего вопроса:  
**1)** Действовать строго согласно поставленному вопросу. Продукция белка в зависимости от фактора класса подразумевает проведения однофакторного дисперсионного анализа. Он прост и хорош собой, однако в таком случае мы воспринимаем класс таким, какой он есть, со всеми его свойствами и не задумываемся над тем, что он из себя представляет внутри.  
**2)** Делаем многофакторный дисперсионный анализ, анализируя составляющие класса как отдельные фактры, взаимодействия которых мы можем учесть. С другой стороны, взаимодействие факторов может маскировать главные эффекты, а если есть значимое взаимодействие, то главные эффекты обсуждать не имеет смысла.  
В таком случае дробить класс на отдельные составляющие мне кажется лишним, достаточно однофакторного анализа!  
  
Делаем отдельный датафрейм для анализа:  
```{r, echo = T, eval = T, include = T}
anova_data <- subset(data, select = c('Mouse', 'ExperimentID', 'BDNF_N', 'class'))
```
  
Есть ли пропущенные значения?  
```{r, echo = T, eval = T, include = T}
sum(is.na(anova_data$BDNF_N))
```
  
Да, три значения - это не так много, в принципе можно просто их отбросить, поскольку замена пропущенных значений на среднее может уменьшить дисперсию внутри групп и увеличит вероятность ошибки первого рода. Можно учесть это на этапе поправки на множественное сравнение, выбрать поправку построже, например, поправка Бонферрони, но делать такую строгую поправку для всего сета из 1080 значений ради трех пропущенных значений мне кажется не очень разумным.  
  
Смотрим, к какому классу, мышке и замеру принадлежат пропущенные значений и избавляемся от них:  
```{r, echo = T, eval = T, include = T}
anova_data[!complete.cases(anova_data), ]
anova_data <- anova_data[complete.cases(anova_data), ]
```
  
Пропущенные значения принадлежат одной мышке из самого малопредставленного класса, однако у этой мышки остаются еще **12** измерений, так что количество мышек внутри класса от отбрасывания *NA* не изменится.  
  
Строим график зависимости уровня продукции BDNF_N от класса мышек, предварительно переставив уровни в порядке следования средних значений красоты ради:
```{r, echo = T, eval = T, include = T}
anova_data$class <- reorder(anova_data$class, anova_data$BDNF_N, FUN = mean)
ggplot(data = anova_data, aes(x = class, y = BDNF_N, colour = class)) +
  stat_summary(geom = 'pointrange', fun.data = mean_cl_normal) + theme_minimal() + 
  labs(x = "Класс", y = "Продукция белка BDNF_N", colour = 'Класс',
       title = "График зависимости уровня продукции BDNF_N от класса")
```
  
Подбираем коэффициенты модели в параметризации индикаторов:  
```{r, echo = T, eval = T, include = T}
mod_treatment <- lm(BDNF_N ~ class, data = anova_data)
coef(mod_treatment)
```
  
**Итерпретация полученных коэффициентов:**  
Первый коэффициент — это средняя продукция белка BDNF_N в классе с-SC-m (контрольных мышкй, нестимулированных к обучению, которых кололи мемантин) на базовом уровне.  
Другие коэффициенты — это разница продукции белка в других классах и в классе с-SC-m (отклонения от базового уровня).  
  
Делаем дисперсионный анализ:  
Воспользуемся функцией *Anova()* из пакета **car**. Эта функция умеет тестировать влияние факторов в определенном порядке. Когда факторов будет больше одного, это станет важно для результатов, поэтому эту функцию нужно любить и жаловать!  
```{r, echo = T, eval = T, include = T}
my_anova <- Anova(mod_treatment)
my_anova
```
  
**Вывод:**  
Уровень продукции белка BDNF_N в зависимости от класса значимо отличается. F~7~, ~1069~ = 18.8, *p* < 0.01).  
  
Результатам тестов можно верить, если выполняются условия применимости:  
Случайность и независимость наблюдений внутри групп,  
Нормальное распределение остатков,  
Гомогенность дисперсий остатков,  
Отсутствие коллинеарности факторов (независимость групп)  
  
Также есть и другие ограничения:  
Лучше работает, если размеры групп примерно одинаковы (сбалансированный дисперсионный комплекс),  
Устойчив к отклонениям от нормального распределения (при равных объемах групп или при больших выборках)  
Отлично, вывод мы получили, однако можно ли ему верить? Проверим! 
  
График расстояния Кука:
```{r, echo = T, eval = T, include = T}
mod_diag <- fortify(mod_treatment)
ggplot(mod_diag, aes(x = 1:nrow(mod_diag), y = .cooksd)) + geom_bar(stat = "identity") + 
  labs(x = "Предсказанные значения", y = "Расстояние Кука", title = "График расстояния Кука") +
  theme_minimal()
```
  
Круто! Выбросов нет!  
  
График остатков от предсказанных значений: 
```{r, echo = T, eval = T, include = T}
ggplot(mod_diag, aes(x = .fitted, y = .stdresid, color = class)) + geom_jitter() + theme_minimal() + 
  labs(colour = 'Класс', title = "График остатков от предсказанных значений")
```
  
Графики остатков от предикторов в модели и не в модели:  
```{r, echo = T, eval = T, include = T}
ggplot(mod_diag, aes(x = class, y = .stdresid)) + geom_boxplot() + theme_minimal() + 
  labs(x = "Класс", title = "График остатков от предикторов в модели и не в модели") 
```
  
 Дисперсии почти одинаковые...  
   
Квантильный график остатков:  
```{r, echo = T, eval = T, include = T}
qqPlot(mod_treatment, id = FALSE)
```
  
Выглядит вполне себе нормально!  
  
Как понять, какие именно группы различаются?  
Дисперсионный анализ говорит нам только, есть ли влияние фактора, но не говорит, какие именно группы различаются. Коэффициенты линейной модели в **summary(mod_treatment)** содержат лишь часть ответа — сравнение средних значених всех групп со средним на базовом уровне. Если нас интересуют другие возможные попарные сравнения, нужно сделать пост хок тест.  
  
Мы сделаем тест, основанный на распределении стьюдентизированного размаха: Тест Тьюки (Tuckey’s Honest Significant Difference, HSD).  
  
```{r, echo = T, eval = T, include = T}
anova_ph <- glht(mod_treatment, linfct = mcp(class = "Tukey"))
summary(anova_ph)
```
  
Таблица результатов пост хок теста практически нечитабельна. Нужны графики!  
  
```{r, echo = T, eval = T, include = T}
MyData <- data.frame(class = factor(levels(anova_data$class), levels = levels(anova_data$class)))
MyData <- data.frame(MyData, predict(mod_treatment, newdata = MyData, interval = "confidence"))
X <- model.matrix(~class, data = MyData)
betas <- coef(mod_treatment)
MyData$fit <- X %*% betas
MyData$se <- sqrt(diag(X %*% vcov(mod_treatment) %*% t(X)))
t_crit <- qt(p = 0.975, df = nrow(anova_data) - length(coef(mod_treatment)))
MyData$lwr <- MyData$fit - t_crit * MyData$se
MyData$upr <- MyData$fit + t_crit * MyData$se

gg_bars <- ggplot(data = MyData, aes(x = class, y = fit)) + 
  geom_bar(stat = "identity", aes(fill = class), width = 0.5) + 
  geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0.1) + 
  labs(x = "Класс", y = "Продукция белка BDNF_N", title = "Столбчатый график зависимости продукции белка от класса") + 
  scale_fill_brewer(name = "Класс", palette = "Dark2") +
  scale_x_discrete(labels = c("c-SC-m", "t-CS-s", "t-CS-m", "c-SC-s", 
                              "t-SC-m", "t-SC-s", "c-CS-m", "c-CS-s")) + 
  theme(legend.position = "none") + theme_minimal()
gg_bars
```
  
### Блок 3. Пробуем построить заведомо провальную линейную модель...  
  
Прежде чем этим заняться, я бы хотела сразу объяснить, почему это изначально заведомо провальное решение:  
Модель продукции одного белка от всех других будет не соответствовать действительности, это можно сказать не глядя.  
1) Многие белки будут **коллинеарными** предикторами, что нарушает условие применимости анализа.  
2) Исходные даные **гетерогенны**, т.е. нельзя просто проанализировать зависимость белка от других белков, не включив в анализ факторы, задающие наши восемь классов.  
3) К тому же обычная lm не учтет структуру наших данных (есть **случайный фактор** особь).  
4) Даже GLMM нас не спасет, т.е. **из-за обилия предикторов будет переобучение**, вылезут в качестве значимых предикторов ложные корреляции (spurious correlations).  
5) Именно поэтому авторы статьи, обладающие достаточным количеством данных используют приемы машинного обучения, а не вот это все...  
  
Что нам остается?  
  
Делать lm не по белкам, а по компонентам после анализа главных компонент, в следующем блоке заданий мы именно этим и занимались, попробуем построить такую модель!  
Не переключайтесь, смотрите продолжене истории после анализа главных компонент!!!
  
### Блок 4. Анализ главных компонент
  
Для начала проведём неметрическое многомерное шкалирование или Nonmetric Multidimensional Scaling (nMDS) с использованием коэффициента различия Брея-Куртиса:  
Данный метод хорош тем, что старается сохранить отношения между объектами!  
nMDS **сохраняет ранг расстояний между объектами**, на ординации имеет смысл только взаиморасположение объектов. Облако точек в осях MDS можно вращать, перемещать, зеркально отражать. Суть ординации от этого не изменится, а значения координат точек в ординации лишены смысла (их вообще можно не приводить на итоговой ординации). Поехали!  
  
```{r, echo = T, eval = T, include = T}  
ord_data <- metaMDS(comm = good_data[, c(-1, -79:-85)], 
                    distance = "bray", autotransform = FALSE)
```
  
После отключения автоматического подбора трансформации данных удается найти решение:
```{r, echo = T, eval = T, include = T}
ord_data$stress
```
  
Мы получили **стресс**, то есть меру качества ординации. Стресс показывает, насколько соответствуют друг другу взаиморасположение точек на плоскости ординации и в исходном многомерном пространстве признаков.
  
```{r, echo = T, eval = T, include = T}
ord_pt <- data.frame(good_data[, 79], scores(ord_data, display = "sites"))
g0 <- ggplot(ord_pt, aes(NMDS1, NMDS2, color = Genotype)) + 
  geom_point()
```

```{r, echo = T, eval = T, include = T}
ord_pt <- data.frame(good_data[, 80], scores(ord_data, display = "sites"))
g1 <- ggplot(ord_pt, aes(NMDS1, NMDS2, color = Treatment)) + 
  geom_point()
```

```{r, echo = T, eval = T, include = T}
ord_pt <- data.frame(good_data[, 81], scores(ord_data, display = "sites"))
g2 <- ggplot(ord_pt, aes(NMDS1, NMDS2, color = Behavior)) + 
  geom_point()
```

```{r, echo = T, eval = T, include = T}
ord_pt <- data.frame(good_data[, 82], scores(ord_data, display = "sites"))
g3 <- ggplot(ord_pt, aes(NMDS1, NMDS2, color = class)) + 
  geom_point()
```

```{r, echo = T, eval = T, include = T}
plot_grid(g0, g1, g2, g3, 
          ncol = 2, nrow = 2) + theme_minimal() + ggtitle(label = "Ординация nMDS")
```
  
Вау, видим, что по Behavior точки дажее неплохо расходятся!  

Наконец, делаем PCA и знакомимся с тем, что у нас получилось:  
```{r, echo = T, eval = T, include = T}
my_pca <- rda(good_data[, c(-1, -79:-85)], scale = TRUE)
head(summary(my_pca))
```
  
Что важного есть в summary:  
1) Eigenvalues (собственные числа)  
Собственные числа показывают дисперсию вдоль осей, заданных собственными векторами. По значениям собственных чисел можно вычислить долю общей изменчивости, связанной с каждой из главных компонент.  
2) Eigenvectors (собственные векторы, факторные нагрузки)  
  
Собственные векторы задают главные компоненты — направления новых осей. Они также называются факторными нагрузками, т.к. это линейные комбинации исходных признаков.  
  
Могут быть рассчитаны как для признаков (Species scores), так и для объектов (Site scores).  
  
Графики ординации:  
  
Биплот с симметричным шкалированием:  
```{r, echo = T, eval = T, include = T}
biplot(my_pca)
```
  
Такой график отражает одновременно и признаки и объекты. Но его нельзя интерпретировать.  
  
Биплот корреляций (график нагрузок):  
```{r, echo = T, eval = T, include = T}
biplot(my_pca, scaling = "species", display = "species")
```
  
Биплот расстояний (график ординации):  
```{r, echo = T, eval = T, include = T}
biplot(my_pca, scaling = "sites", display = "sites")
```
  
График ординации помощью **ggplot2** в осях первых двух главных компонент:
```{r, echo = T, eval = T, include = T}
df_scores <- data.frame(good_data,
                        scores(my_pca, display = "sites", choices = c(1, 2, 3), scaling = "sites"))

gg1 <- ggplot(df_scores, aes(x = PC1, y = PC2)) + 
  geom_point(aes(color = Genotype), alpha = 0.5) +
  coord_equal(xlim = c(-1.2, 1.2), ylim = c(-1.2, 1.2)) + theme_minimal()
```

```{r, echo = T, eval = T, include = T}
gg2 <- ggplot(df_scores, aes(x = PC1, y = PC2)) + 
  geom_point(aes(color = Treatment), alpha = 0.5) +
  coord_equal(xlim = c(-1.2, 1.2), ylim = c(-1.2, 1.2)) + theme_minimal()
```

```{r, echo = T, eval = T, include = T}
gg3 <- ggplot(df_scores, aes(x = PC1, y = PC2)) + 
  geom_point(aes(color = Behavior), alpha = 0.5) +
  coord_equal(xlim = c(-1.2, 1.2), ylim = c(-1.2, 1.2)) + theme_minimal()
```

```{r, echo = T, eval = T, include = T}
gg4 <- ggplot(df_scores, aes(x = PC1, y = PC2)) + 
  geom_point(aes(color = class), alpha = 0.5) +
  coord_equal(xlim = c(-1.2, 1.2), ylim = c(-1.2, 1.2)) + theme_minimal()

plot_grid(gg1, gg2, gg3, gg4,
          ncol = 2, nrow = 2) + theme_minimal() + ggtitle(label = "Ординация в осях главных компонент")
```
  
Интерпретация PCA:  
В самом начале необходимо понять, какой вклад вносит каждая компонента. Для этого есть условные коэффициенты, а также это можно проанализировать с использованием графика собственных чисел:  
```{r, echo = T, eval = T, include = T}
eigenvals(my_pca)
```

```{r, echo = T, eval = T, include = T}
bstick(my_pca)
```

```{r, echo = T, eval = T, include = T}
screeplot(my_pca, type = "lines", bstick = TRUE)
```
  
Другим простым способом для объяснения того, какой вклад вносит та или иная компонента – посмотреть в summary() **Proportion Explained**. Это можно визуализировать:  

```{r, echo = T, eval = T, include = T}
pca_summary <- summary(my_pca)
pca_result <- as.data.frame(pca_summary$cont)
plot_data <- as.data.frame(t(pca_result[c("Proportion Explained"), ]))
plot_data$component <- rownames(plot_data)

ggplot(plot_data, aes(component, `Proportion Explained`)) + 
  geom_bar(stat = "identity") + theme_minimal()
```  
  
Здорово, теперь можно отобрать эти девять главных компонент для построения линейной модели! УРААА!!!
  
Интерпретация компонент:  
Факторные нагрузки оценивают вклады переменных в изменчивость по главной компоненте:  
1) модуль значения нагрузки — величина вклада  
2) знак значения нагрузки — направление вклада  
  
```{r, echo = T, eval = T, include = T}
scores(my_pca, display = "species", choices = c(1, 2, 3), scaling = 0)
```
  
Для каждой компоненты:  
Высокие положительные нагрузки по главным компонентам у переменных значат, чем *больше* значение компоненты, тем больше продукция белка.  
Высокие отрицательные нагрузки у переменных значат, чем меньше значение компоненты, тем *больше* продукция.  
  
На последок еще одна визуализация PCA:  
```{r, echo = T, eval = T, include = T}
pca_base <- prcomp(good_data[, c(-1, -79:-85)], scale = TRUE)
fviz_pca_ind(pca_base,
             geom.ind = "point", # show points only (nbut not "text")
             col.ind = good_data$`data$class`, # color by groups
             palette = "Dark2",
             addEllipses = TRUE, # Concentration ellipses
             legend.title = "Class"
             )
```
  
Окончательная красота c 3D визуализацией:  
```{r, echo = T, eval = T, include = T}
pca3d(pca_base, group=good_data$`data$class`)
```  
  
##### Возвращаемся к истории с линейной моделью    
Теперь мы вооружены всеми данными с анализа главных компонент и можем снова вернуться к **lm**.  
Создаем наш маленький датафрейм для анализа:  
```{r, echo = T, eval = T, include = T}
protein <- good_data$ERBB4_N
pca1 <- pca_base$rotation[, 1]
pca2 <- pca_base$rotation[, 2]
pca3 <- pca_base$rotation[, 3]
pca4 <- pca_base$rotation[, 4]
pca5 <- pca_base$rotation[, 5]
pca6 <- pca_base$rotation[, 6]
pca7 <- pca_base$rotation[, 7]
pca8 <- pca_base$rotation[, 8]
pca9 <- pca_base$rotation[, 9]
lm_data <- as.data.frame(cbind(protein, pca1, pca2, pca3, pca4, pca5, pca6, pca7, pca8, pca9))
```
  
##### Строим модель:  
```{r, echo = T, eval = T, include = T}  
mod1 <- lm(protein ~ ., data = lm_data)
```  
  
##### Анализ полученной модели:  
  
1) Проверка на линейность взаимосвязи с помощью графика остатков предсказанных значений:  
```{r, echo = T, eval = T, include = T}
mod1_diag <- fortify(mod1)
gg_resid_1 <- ggplot(data = mod1_diag, aes(x = .fitted, y = .stdresid)) + 
  geom_point() + 
  geom_hline(yintercept = 0) +
  geom_smooth(method = "lm") +
  geom_hline(yintercept = 2, color = "red") +
  geom_hline(yintercept = -2, color = "red") +
  theme_minimal()
gg_resid_2 <- gg_resid_1 + labs(x = "Предсказанные значения", y = "Остатки", title = "График остатков от предсказанных значений")
gg_resid_2
```  
  
Выглядит боле менее равномерно, однако далеко от идеала!  
  
2) Проверка влиятельных наблюдений с помощью графика расстояний Кука:  
```{r, echo = F, eval = T, include = T}
gg_cook_1 <- ggplot(mod1_diag, aes(x = 1:nrow(mod1_diag), y = .cooksd)) + 
  geom_bar(stat = "identity") +
  labs(x = "Предсказанные значения", y = "Расстояние Кука", title = "График расстояния Кука") + theme_minimal()
gg_cook_1
```
  
Все хорошо, влиятельные наблюдения отсутствуют!  
  
3) Нормальность распределения остатков:  
```{r, echo = F, eval = T, include = T}
qqPlot(mod1, xlab = "Теоретические квантили", ylab = "Стьюдентизированные остатки", main = "Квантильный график остатков", id = FALSE)
```
  
Можно сказать, что остатки распределены даже более менее нормально!  
  
Посмотрим на график остатков от предикторов, вошедших в данную модель:  
```{r, echo = F, eval = T, include = T}
res_1 <- gg_resid_1 + aes(x = pca1) + theme_minimal()
res_2 <- gg_resid_1 + aes(x = pca2) + theme_minimal()
res_3 <- gg_resid_1 + aes(x = pca3) + theme_minimal()
res_4 <- gg_resid_1 + aes(x = pca4) + theme_minimal()
res_5 <- gg_resid_1 + aes(x = pca5) + theme_minimal()
res_6 <- gg_resid_1 + aes(x = pca6) + theme_minimal()
res_7 <- gg_resid_1 + aes(x = pca7) + theme_minimal()
res_8 <- gg_resid_1 + aes(x = pca8) + theme_minimal()
res_9 <- gg_resid_1 + aes(x = pca9) + theme_minimal()

grid.arrange(res_1, res_2, res_3, res_4, res_5, res_6, res_7, res_8, res_9, nrow = 3, top = "График остатков от предикторов в модели")
```  
  
Четких нелинейных паттерном на данных графиках я не вижу, что заставляет задуматься, что, возможно, все не так плохо, как мы изначально предполагали...  
  
Наконец, ознакомимя с саммари модели:
```{r, echo = F, eval = T, include = T}
summary(mod1)
```
  
Наибольший по модулю коэффициент обладает переменная **pca4**. Построим от нее график предсказания стоимости:  
```{r, echo = F, eval = T, include = T}
MyData <- data.frame(
  pca4 = seq(min(lm_data$pca4), max(lm_data$pca4), length.out = 1080),
  pca1 = mean(lm_data$pca1),
  pca2 = mean(lm_data$pca2),
  pca3 = mean(lm_data$pca3),
  pca5 = mean(lm_data$pca5),
  pca6 = mean(lm_data$pca6),
  pca7 = mean(lm_data$pca7),
  pca8 = mean(lm_data$pca8),
  pca9 = mean(lm_data$pca9))

Predictions <- predict(mod1, newdata = MyData,  interval = 'confidence')
MyData <- data.frame(MyData, Predictions)

Pl_predict <- ggplot(MyData, aes(x = lm_data$protein, y = fit)) + 
  geom_ribbon(alpha = 0.2, aes(ymin = lwr, ymax = upr)) +
  geom_line() + 
  ggtitle("График предсказания продукции белка от главной компоненты 4") + theme_minimal() + 
  labs(x = "Главная компонента 4", y = "Предсказанные значения")

Pl_predict
```
  
Отличный способ проиллюстрировать, что не надо строить линейные модели от чего попало и не учитывать важные группирующие факторы в модели. ВСЕ! :>
    
### Блок 5. Magic fantasy. Дифференциальная экспрессия...  
