---
title: "Отчет по проекту_1. Предобработка данных"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

check.packages <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg)) 
        install.packages(new.pkg, dependencies = TRUE)
    sapply(pkg, require, character.only = TRUE)
}

packages <- c("plyr", "readr", "dplyr", "nortest", "ggplot2", "coin", "jmuOutlier", "car", "cowplot")
check.packages(packages)
```

### 0. Организационная часть

Для работы необходимо задать путь до директории, содержащей распакованные файлы для работы над проектом:
```{r, echo = T, eval = T, include = T}
dir_path <- '/home/yulia/Rcourse/data/Data/'
```
Список используемых в работе библиотек: **plyr**, **readr**, **dplyr**, **nortest**, **ggplot2**, **coin**, **jmuOutlier**, **car**, **cowplot**.

### 1. Объединение данных в единую таблицу

Мною была написана пользовательская функция **load_unite_csv**, которая подгружает csv файлы и объединяет их в один датафрейм:
```{r, echo = T, eval = T, include = T}
load_unite_csv <- function(path){
  mydir <- path
  myfiles <- list.files(path=mydir, pattern = "*.csv", full.names = TRUE)
  dat_csv <- ldply(myfiles, read_csv)
}
```
Эта функция требует на вход путь до папки с csv файлами и объединяет их в единый датафрейм.
В нашем случае очень удобно в качестве пути использовать заранее установленную рабочую директорию.  
Применим функцию нашим данным:
```{r, echo = T, eval = T, include = T, message = F}
full_df <- load_unite_csv(path = dir_path)
```
### 2. Первый взгляд на данные
Посмотрим на структуру наших данных:
```{r, echo = T, eval = T, include = T}
str(full_df)
```
Замечаем, что параметры *Rings*, *Sex*, *~~Rock-n-roll~~* *Length* в датафрейме явдляются character type, а не num... Это странно, поэтому было необходимо выяснить, а какие значения бывают у этих параметров:  
Для *Rings*:
```{r, echo = F, eval = T, include = T}
unique(full_df$Rings)
```
Для *Sex*:
```{r, echo = F, eval = T, include = T}
unique(full_df$`Sex (1 – male, 2 – female, 3 – uvenil)`)
```
Для *Length*:
  ```{r, echo = F, eval = T, include = T}
tail(unique(full_df$Length))
```
Замечаем совершеннейшее безобразие, которое случилось во время занесения студентами данных в поле. Устраняем безоборазие:
```{r, echo = T, eval = T, include = T, warning = F}
full_df$Rings <- revalue(full_df$Rings, c("nine" = "9"))
full_df$`Sex (1 – male, 2 – female, 3 – uvenil)` <-
  revalue(full_df$`Sex (1 – male, 2 – female, 3 – uvenil)`, c("three" = "3", "one" = "1", "male" = "1"))
full_df$Length <- revalue(full_df$Length, c("No data! I forgot to mesure it!(" = "NA"))
```
Продолжаем наводить порядок. Делаем *Rings* и *Length* числовыми переменными, поскольку идеологически они являются таковыми:
```{r, echo = T, eval = T, include = T, warning = F}
full_df <- full_df %>% mutate(Rings = as.numeric(Rings), Length = as.numeric(Length))
```
Переименовываем параметр Sex и сделаем его фактором, как ему и положено (заодно устраняем опечатку в слове "juvenile":
```{r, echo = T, eval = T, include = T}
full_df$`Sex (1 – male, 2 – female, 3 – uvenil)` <- 
  factor(full_df$`Sex (1 – male, 2 – female, 3 – uvenil)`, 
         levels = c("1", "2", "3"),
          labels = c("male", "female", "juvenile"))
colnames(full_df)[2] <- "Sex"
```
Ура! Наши данные почти готовы к обработке!
Для начала нужно проверить, есть ли в нашем датафрейме пропущенные значения и сколько их:
```{r, set-options, echo = T, eval = T, include = T}
options(width = 100)
sum(colSums(is.na(full_df)))
```
В нашем датафрейме **`r sum(colSums(is.na(full_df)))`** пропущенных значений.  
Мы можем посмотреть на них поближе:
```{r, echo = T, eval = T, include = T}
full_df[!complete.cases(full_df), ]
```
Что же нам с ними делать?  
Существует практика замены NA на среднее значение, однако для параметра Sex такое вовсе не предоставляется возможным, представитель раздельнополых видов моллюсков же не может быть немножко мальчиком и немножко девочкой в норме!  
В нашем датафрейме количество NA составляет меньше процента от всех наблюдений, поэтому в данном случае их можно просто исключить из анализа:
```{r, echo = T, eval = T, include = T}
final_df <- full_df[complete.cases(full_df), ]
```
### 3. Расчет среднего значения и стандартного отклонения переменной Length для моллюсков разного пола
```{r, echo = T, eval = T, include = T}
final_df %>% group_by(Sex) %>% summarise(mean(Length), sd(Length))
```
### 4. Расчет доли моллюсков с Heigth не больше 0.165 (в процентах)
```{r, echo = T, eval = T, include = T}
height_less_0.166 <- nrow(final_df %>% filter(Height < 0.166))/nrow(final_df)*100
```
Процент моллюсков с высотой не более 0.165 равен **`r height_less_0.166`**.

### 5. Расчет Значения переменной Length, которое выше, чем у 92% от всех наблюдений
```{r, echo = T, eval = T, include = T}
quantile(final_df$Length, probs = 0.92)
```
Значение равно **`r quantile(final_df$Length, probs = 0.92)`**.

### 6. Значения переменной Length после Z-стандартизации, записанные в переменую Lenght_z_scores
```{r, echo = T, eval = T, include = T}
Lenght_z_scores <- scale(final_df$Length)
```

### 7. Сравнение между собой диамеметров моллюсков с числом колец 5 и 15
Сначала нужно проверить, нормально ли распределение диаметров моллюсков.  
Посмотрим на них глазами:
```{r, echo = T, eval = T, include = T}
ggplot(final_df, aes(sample = Diameter)) + geom_qq(color = "grey") + geom_qq_line(color = "blue") +
  labs(x = "Теоретические квантили", y = "Наблюдаемые значение переменных", title = "График квантилей для значений диаметра") +
  theme_minimal()
```

Как-то это не очень похоже на нормальное распределение...  
Проводим тест Шапиро-Уилка на нормальность распределения:
```{r, echo = T, eval = T, include = T}
norm_test_1 <- shapiro.test(full_df$Diameter)
norm_test_1
```
Значение p-value < 0.05, принимаем альтернативную гипотезу о том, что случайная величина распределена ненормально.  
На самом деле лучше использовать тест Колмогорова-Смирнова в модифиации Lilliefors, его мы тоже проведем:
```{r, echo = T, eval = T, include = T}
norm_test_2 <- lillie.test(full_df$Diameter)
norm_test_2
```
Значение p-value < 0.05, принимаем альтернативную гипотезу о том, что случайная величина распределена ненормально.  
Думаем, что нам делать с этой информацией. А пока посмотрим на наши данные на графике:
```{r, echo = T, eval = T, include = T, message = F}
ggplot(final_df, aes(x = Diameter)) + 
  geom_histogram(col = "grey", fill = "pink", alpha = 0.7) + 
  theme_minimal() + 
  labs(x = "Диаметр", y = "Число наблюдений", title = "Распределение значений диаметра")
```

Также посмотрим на плотность распределения признака диаметр (Diameter) для моллюсков с числом колец (Rings) равным 5 и 15:
```{r, echo = T, eval = T, include = T, message = F}
local_df_1 <- final_df %>% filter(Rings == 5 | Rings == 15) %>% select(Diameter, Rings)
ggplot(local_df_1, aes(x = Diameter, fill = factor(Rings))) + 
  geom_density(alpha = 0.5, color = "grey") + 
  labs(x = "Диаметр", y = "Число колец") + 
  scale_fill_discrete(name="Число колец") +
  ggtitle("График плотности распределения величины диаметра\nдля моллюскомв с числом колец 5 и 15") +
  scale_color_brewer(palette = "Accent")
```
  
Возвращаемся к нашим баранам. Поскольку наше распределение признака выглядит как не очень нормальное, то нужно использовать непараметрический критерий Уилкоксона, но можно и t-test, т.к это не противоречит условию его применимости (большой объем выборки ИЛИ нормальное распределение). Поскольку данный проект является учебным, то интересно провести оба анализа.  
  
Сначала важно сформулировать нулевую и альтернативную гипотезы!  
*H~0~*: моллюски с числом колец 5 и 15 имеют одинаковый диаметр.  
*H~1~*: моллюски с числом колец 5 и 15 имеют разный диаметр.
  
#### Расчитываем критерий Уилкоксона:
```{r, echo = T, eval = T, include = T}
test_1_wilcox <- wilcox.test(Diameter ~ Rings, data = local_df_1, subset = Rings %in% c(5, 15))
test_1_wilcox 
```
**Вывод**: диаметр статистически значимо отличается у моллюсков с числом колец 5 и 15 (p-value < 0.05).
  
Теперь разбираемся с t-критерием. В большинстве случаев рекомендуется делать двухвыборочный t-test, поскольку очень редко мы можем знать наверняка "вектор различий" между двумя группами (по этой причине двухвыборочные тесты являются более строгими). Однако в данном примере логично обратиться к биологической чуйке и предположить, что при большом числе колец диаметр моллюска будет явно больше, а не меньше. Но любопытства ради можно посчитать и одновыборочный, и двухвыборочный t-test.  
 
  
#### Одновыборочный t-test:  
*H~0~*: моллюски с числом колец 5 и 15 имеют одинаковый диаметр.  
*H~1~*: моллюски с числом колец 5 имеют меньший диаметр, чем моллюски с 15 кольцами.
```{r, echo = T, eval = T, include = T}
test_2_ttest <- t.test(local_df_1$Diameter)
test_2_ttest
```
**Вывод**: диаметры моллюсков с числом колец 5 меньше, чем диаметры моллюсков с числом колец 15 (p-value < 0.05).
  
  
#### Двухвыборочный t-test:
*H~0~*: моллюски с числом колец 5 и 15 имеют одинаковый диаметр.  
*H~1~*: моллюски с числом колец 5 и 15 имеют разные диаметры.
```{r, echo = T, eval = T, include = T}
test_3_ttest <- t.test(local_df_1$Diameter ~ local_df_1$Rings)
test_3_ttest
```
**Вывод**: диаметр статистически значимо отличается у моллюсков с числом колец 5 и 15 (p-value < 0.05).

### 8. Проверка взаимосвязи переменной Diameter и Whole_weigth
Опять же сначала посмотрим глазками:
```{r, echo = T, eval = T, include = T}
ggplot(data = final_df, aes(x = Diameter, y = Whole_weight)) + 
  geom_point(color = "grey") + theme_minimal() +
  labs(x = 'Диаметр', y = 'Вес целиком', title = 'График зависимости значений диаметра и веса целиком')
```

Выглядит как повод изучать взаимосвязь более подробно!  
Зависимость диаметра от веса однозначно есть, но она степенная, а не линейная.  
С учетом нелинейной составляющей взаимосвязи и ненормальности распределения значений диаметра, использовать коэффициент корреляции Пирсона будет некорректным.  
  
Расчитаем коэффициент корреляции Спирмана!  
*H~0~*: коэффициент корреляции равен нулю.
*H~1~*: коэффициент корреляции значимо отличается от нуля.
```{r, echo = T, eval = T, include = T, message = T}
cor_test <- cor.test(final_df$Diameter, final_df$Whole_weight, method = "spearman")
cor_test
```
Коэффициент корреляции статистически значимо отличается от нуля (p-value < 0.05).  

Все хорошо, но для ранговых коэффициентов существует проблема совпадающих рангов, что приводит к приблизительной оценке коэффициента корреляции и уровня значимости. Как это лечится?  
Достоверность корреляции можно оценить пермутационным методом!

#### Пермутационный метод:  
```{r, echo = T, eval = T, include = T, message = T}
perm_test <- perm.cor.test(final_df$Diameter, final_df$Whole_weight, "two.sided", "spearman" )
perm_test
```

#### Асимптотический тест:
```{r, echo = T, eval = T, include = T, message = T}
add_test <- spearman_test(final_df$Whole_weight ~ final_df$Diameter)
add_test
```
Оба теста также подтвеждают наличие статистически значимой корреляции между двумя переменными (p-value < 0.05).


#### Попробуем в уход от нелинейности к линейной зависимости:
Наконец, визуализируем нашу чудесную нелинейную зависимость, в линейном виде!  
Воспользуемся знанием о том, что вес линейно зависит от объема, а объем растет по кубу от линейного размера (диаметр как раз является линейным размером). Построим график зависимости куба диаметра зверушки от ее веса:
```{r, echo = T, eval = T, include = T}
ggplot(data = final_df, aes(x = Diameter, y = Whole_weight ^ (1/3))) + 
  geom_point(color = "grey") + theme_minimal() + geom_smooth(method = 'lm') + 
  labs(x = 'Диаметр', y = 'Вес целиком', title = 'График зависимости куба диаметра и веса моллюска')
```
    
Отлично, после математических преобразований можно проверить в последний раз нашу зависимость на предмет корреляции!  
Теперь можно смело рассчитывать тест корреляции Пирсона, поскольку наша зависимость стала линейной!  
*H~0~*: коэффициент корреляции равен нулю.  
*H~1~*: коэффициент корреляции значимо отличается от нуля.
```{r, echo = T, eval = T, include = T}
cor.test(final_df$Diameter, (final_df$Whole_weight) ^ (1/3))
```
Коэффициент корреляции статистически значимо отличается от нуля (p-value < 0.05).  
Отлично! Ура!

### 9. Свежий взгляд со стороны
#### Проведем разведочный анализ данных:
```{r, echo = T, eval = T, include = T, message = T}
pairs(final_df)
```
  
Что можно сказать?  
Можно подозревать, что есть зависимость между возрастом и весовыми метриками... Проверим глазками, существует ли зависимость между **весом** и **половой принадлежностью** моллюска:
```{r, echo = T, eval = T, include = T, message = F}
ggplot(final_df, aes(x = final_df$Whole_weight, fill = factor(Sex, labels = c("Самцы", "Самки", "Ювенили")))) + 
  geom_density(alpha = 0.5, color = "grey") + 
  labs(x = "Вес", y = "Количество особей") + 
  scale_fill_discrete(name="Особь") +
  ggtitle("График плотности распределения величины веса особи\nв зависимости от пола моллюска") +
  scale_color_brewer(palette = "Accent")
```
  
Действительно, что-то в этом есть, особенно сильно ювенили отличаются от самцов и самок!  
  
На самом деле стоит заметить, что даже половозрелые самцы и самки на графике немного отличаются друг от друга по весу.  
Посмотрим глазами на распределение признака веса:
```{r, echo = T, eval = T, include = T, message = F}
ggplot(final_df, aes(sample = Whole_weight)) + geom_qq(color = "grey") + geom_qq_line(color = "blue") + 
  labs(x = "Теоретические квантили", y = "Наблюдаемые значение переменных", title = "График квантилей для значений диаметра") +
  theme_minimal()
```
   
Опять же на нормальное распределение это не особо похоже...
```{r, echo = T, eval = T, include = T, message = F}
ggplot(final_df, aes(x = Whole_weight)) + 
  geom_histogram(col = "grey", fill = "pink", alpha = 0.7) + 
  theme_minimal() + 
  labs(x = "Диаметр", y = "Число наблюдений", title = "Распределение значений диаметра")
```
  
Да, признак явно распределен ненормально. Но мы это увидели только глазками! Время для статистических тестов:
```{r, echo = T, eval = T, include = T}
norm_test_3 <- lillie.test(full_df$Whole_weight)
norm_test_3
```
Значение p-value < 0.05, принимаем альтернативную гипотезу о том, что случайная величина распределена ненормально.  

Возможно, имеет смысл повозиться с дисперсионным анализом?

#### Проверка условий применимости дисерисионного анализа
Подбираем коэффициенты модели в параметризации эффектов:
```{r, echo = T, eval = T, include = T}
mod_treatment <- lm(Whole_weight ~ Sex, data = final_df)
coef(mod_treatment)
```
Данные для графиков остатков:
```{r, echo = T, eval = T, include = T}
mod_diag <- fortify(mod_treatment)
```
График расстояния Кука:
```{r, echo = T, eval = T, include = T}
ggplot(mod_diag, aes(x = 1:nrow(mod_diag), y = .cooksd)) + geom_bar(stat = "identity") + theme_minimal()
```
   
Выбросов нет, все хорошо.

График остатков от предикторов в модели и не в модели:
```{r, echo = T, eval = T, include = T}
ggplot(mod_diag, aes(x = Sex, y = .stdresid)) + geom_boxplot() + theme_minimal()
```
  
Дисперсии почти одинаковые.

Квантильный график остатков (график построен с помощью qqPlot из пакета car):
```{r, echo = T, eval = T, include = T}
qqPlot(mod_treatment, xlab = "Теоретические квантили", ylab = "Стьюдентизированные остатки", main = "Квантильный график остатков", id = FALSE)
```
  
Распределение остатков явно отличается от нормального, что **нарушает условие применимости** дисперсионного анализа.  
Поскольку у нас не так много уровней дискретной переменной (всего три), то можно сделать попарные сравнения с помощью t-теста.

#### Попарные сравнения весов моллюсков с разной половой принадлежностью:

##### 1. Сравнение весов ювенилей и самок
*H~0~*: ювенили и самки имеют одинаковый вес.  
*H~1~*: ювенили и самки имеют разный вес.
```{r, echo = T, eval = T, include = T}
local_df_2 <- final_df %>% filter(Sex == "juvenile" | Sex == "female") %>% select(Whole_weight, Sex)
test_4_ttest <- t.test(Whole_weight ~ Sex, data = local_df_2, subset = Sex %in% c("juvenile", "female"))
test_4_ttest
```

##### 2. Сравнение весов ювенилей и самцов
*H~0~*: ювенили и самцы имеют одинаковый вес.  
*H~1~*: ювенили и самцы имеют разный вес.
```{r, echo = T, eval = T, include = T}
local_df_3 <- final_df %>% filter(Sex == "juvenile" | Sex == "male") %>% select(Whole_weight, Sex)
test_5_ttest <- t.test(Whole_weight ~ Sex, data = local_df_3, subset = Sex %in% c("juvenile", "male"))
test_5_ttest
```

##### 3. Сравнение весов самцов и самок
*H~0~*: самцы и самки имеют одинаковый вес.  
*H~1~*: самцы и самки имеют разный вес.
```{r, echo = T, eval = T, include = T}
local_df_4 <- final_df %>% filter(Sex == "male" | Sex == "female") %>% select(Whole_weight, Sex)
test_6_ttest <- t.test(Whole_weight ~ Sex, data = local_df_4, subset = Sex %in% c("male", "female"))
test_6_ttest
```
Поскольку мы проводим множественное сравнение, то необходимо провести поправку на множественнео сравнение!  
Самой простой, интуитивно понятной, но жесткой поправкой является поправка Бонферони. В таком случае уровень значимости для каждого сравнения необходимо уменьшить в три раза.
Даже после такой жесткой поправки все три попарных сравнения показали, что особи с разной половой принадлежностью достоверно отличаются друг от друга (p-value < `r 0.05/3`)!  
Ура!  
   
Что еще можно сделать?  

##### Построение линейной модели зависимости веса от раличных предикторов
Вес моллюска может зависить не только от пола, но и возраста, веса отдельных частей моллюска... нужны модели.  
Ищем отскоки с помощью точечных диаграмм Кливленда
```{r, echo = T, eval = T, include = T}
gg_dot <- ggplot(final_df, aes(y = 1:nrow(final_df))) + geom_point() + ylab('Индекс')
Pl1 <- gg_dot + aes(x = Rings) + xlab("Кольца")
Pl2 <- gg_dot + aes(x = Sex) + xlab("Пол")
Pl3 <- gg_dot + aes(x = Length) + xlab("Длина")
Pl4 <- gg_dot + aes(x = Diameter) + xlab("Диаметр")
Pl5 <- gg_dot + aes(x = Height) + xlab("Высота")
Pl6 <- gg_dot + aes(x = Whole_weight) + xlab("Вес целиком")
Pl7 <- gg_dot + aes(x = Shucked_weight) + xlab("Shucked вес")
Pl8 <- gg_dot + aes(x = Viscera_weight) + xlab("Вес внутренностей")
Pl9 <- gg_dot + aes(x = Shell_weight) + xlab("Вес ракушки")
plot_grid(Pl1, Pl2, Pl3, Pl4, Pl5, Pl6, 
          Pl7, Pl8, Pl9, ncol = 3, nrow = 3) + theme_minimal()
```
   
Видим, что все более менее, но для признака высоты есть два подозрительно отскакивающих значения.  
Что это за значения?
```{r, echo = T, eval = T, include = T}
final_df[final_df$Height > 0.5, ]
```
Для того, чтобы отбросить эти значения, нужно быть точно уверенным, что у этого есть достаточные биологические обоснования. У нас для этого основания есть. Совершенно другая высота ракушки подразумевает совершенно другую ее форму. Есть подозрения, что студенты случайно напортачили с определением вида этих двух особоей, поэтому они просто не принадлежат исследуемому виду. Можем смело избавиться от этих значений:
```{r, echo = T, eval = T, include = T}
df_for_task_9 <- final_df[final_df$Height < 0.5, ]
```
Вспомним условия применимости множественной линейной регрессии:  
а) Линейная связь между зависимой переменной и предикторами  
б) Независимость значений зависимой переменной друг от друга  
в) Нормальное распределение зависимой переменной для каждого уровня значений предиктора  
г) Гомогенность дисперсий зависимой переменной для каждого уровня значений предиктора  
д) Отсутствие коллинеарности предикторов  
  
Еще из разведочного графика мы увидели, что у нас много проблем с нарушениями условий применимости множественной регрессии. Во первых, зависимая переменная не со всеми предикторами имеет линейную связь. Вес однозначно нелинейно зависит от длины раковины и ее диаметра, однако это можно поправить, возведя в предиктор в необходимую степень. Нормальность распределения переменной мы проверяли ранее, нормальным распределением тут и не пахнет. И самой большой проблемой является **наличие коллинеарности** предикторов.  
Помятуя принцип *garbage in -> garbage out*, в жизни заниматься построением модели с такими данными было бы кощунством. Да, можно удалить из модели зависимые друг от друга предикторы, вычисляя коэффициент раздутия модели (VIF), но в целом данные для построения модели не очень хороши.